{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer_Neural_Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp6GR3YXCn8b"
      },
      "source": [
        "# Neural Network - Cancer Data\n",
        "\n",
        "This project mainly focuses on the understanding and implementation of Neural Networks in Python from scratch. I have used Wisconsin Breast Cancer Dataset for this project. The main goal of this project is to predict the cancer malignancy with a neural network.\n",
        "\n",
        "## Dataset Information:\n",
        "\n",
        "   - Number of Attributes - 11\n",
        "        - id\n",
        "        - clump_thickness\n",
        "        - cell_uniformity\n",
        "        - cellshape_uniformity\n",
        "        - adhesion\n",
        "        - cell_size\n",
        "        - nuclei\n",
        "        - chromatin\n",
        "        - nucleoli\n",
        "        - mitoses\n",
        "        - Class\n",
        "\n",
        "We will be predicting the Class attribute based on the other attributes mentioned above.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycSHWoECDwYn"
      },
      "source": [
        "## Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK3gUtsJCpIT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z87TuArjDFGy"
      },
      "source": [
        "## Implementation of Neural Network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if9uzSNWHWqR"
      },
      "source": [
        "### Structure of a Neural Network:\n",
        "   - Neural Network consists of an input layer, hidden layers and an output layer.\n",
        "   - Weights and biases associated with each layer.\n",
        "   - Activation function associated with each hidden layer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJiooMRiKcAg"
      },
      "source": [
        "## Weight Initialization:\n",
        "\n",
        "In this function the weights are intialized randomly in the range of [-1, 1]. This function takes nodes as an input which is nothing but the number of nodes in each layer and it returns a multi dimensional array called weights and each element in the array represents a connection between previous and current layer. Biases are also included along with the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buB0KsawuvCg"
      },
      "source": [
        "def weight_initializer(nodes):\n",
        "    hidden_layers, weights = len(nodes), []\n",
        "    \n",
        "    for i in range(1, hidden_layers):\n",
        "        weight = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)] for j in range(nodes[i])]\n",
        "        weights.append(np.matrix(weight))\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMUye_uZDGDI"
      },
      "source": [
        "## Neural Network:\n",
        "\n",
        "This function is used to train the network for the given number of iterations. It takes training data, validation data, number of iterations, learning rate and list of integers as inputs. Accuracies obtained from the train and validation data are printed for each iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks3Y2oNuwAE3"
      },
      "source": [
        "def neural_network(X_train, Y_train, X_val=None, Y_val=None, iterations=10, nodes=[], rate=0.15):\n",
        "    hiddenLayers = len(nodes) - 1\n",
        "    weights = weight_initializer(nodes)\n",
        "\n",
        "    for iteration in range(1, iterations+1):\n",
        "        weights = train_neuralNet(X_train, Y_train, rate, weights)\n",
        "\n",
        "        #Print the accuracy of training and validation after every 20 iterations\n",
        "        if(iteration % 20 == 0):\n",
        "            print(\"Iteration {}\".format(iteration))\n",
        "            print(\"Accuracy on train data:{}\".format(model_accuracy(X_train, Y_train, weights)))\n",
        "            if X_val.any():\n",
        "                print(\"Accuracy on validation data:{}\".format(model_accuracy(X_val, Y_val, weights)))\n",
        "                        \n",
        "    return weights"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qKo7kPnNDAI"
      },
      "source": [
        "##Note :\n",
        "\n",
        "The weights need to be continuously adjusted across each iteration to increase the accuracy of the network. In each iteration the network is trained using forward/backward propagation algorithm. First, the input is passed through the network and output is calculated and then, according to the error of output, the weights are updated backwards. So basically, the error is propagated backward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iroK0pMDDHFK"
      },
      "source": [
        "## Feed Forward Propagation:\n",
        "\n",
        "Each layer receives an input and computes the output which is calculated by passing the dot product of input and weights of the layer to a activation function. I used \"Sigmoid\" activation function. The output of each layer is the input for the next layer.\n",
        "\n",
        "In this network, the information moves in a single direction input to hidden nodes followed by output nodes. No cycles or loops detected in the network. In this function, weights, number of hidden layers are taken as inputs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk3_0h6CwAHa"
      },
      "source": [
        "def Feed_Forward(x, weights, hidden_layers):\n",
        "    output, currentLayer_input = [x], x\n",
        "\n",
        "    for j in range(hidden_layers):\n",
        "        activation = Sigmoid(np.dot(currentLayer_input, weights[j].T))\n",
        "        output.append(activation)\n",
        "        currentLayer_input = np.append(1, activation)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_ZlY9ZrDIFJ"
      },
      "source": [
        "## Back Propagation:\n",
        "\n",
        "In this function the output, weights and number of hidden layers are passed as inputs. The flow will be backwards, from output layer to the last hidden layer and follows. The weights and biases are adjusted accordingly.\n",
        "\n",
        "In this function, error rate will be calculated. The error will be propagated backwards and the weights are adjusted. \n",
        "  - Delta Calculation : error of next layer multiplied by sigmoid derivative of current layer.\n",
        "  - Weights and biases : Delta multiplied with output of previous layer, rate and sum it with weight of previous layer. Biases are updated in the same way.\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reSiMijCwAKy"
      },
      "source": [
        "def BackPropagation(y, output, weights, hidden_layers):\n",
        "    final_output = output[-1]\n",
        "    error = np.matrix(y - final_output) #Calculate the error at last output\n",
        "    \n",
        "    #Back propagate the error\n",
        "    for j in range(hidden_layers, 0, -1):\n",
        "        currentLayer_output = output[j]\n",
        "        \n",
        "        if(j > 1):\n",
        "            # Add previous output\n",
        "            previous_output = np.append(1, output[j-1])\n",
        "        else:\n",
        "            previous_output = output[0]\n",
        "        \n",
        "        delta = np.multiply(error, sigmoidDerivative(currentLayer_output))\n",
        "        weights[j-1] += rate * np.multiply(delta.T, previous_output)\n",
        "\n",
        "        weight = np.delete(weights[j-1], [0], axis=1) \n",
        "        error = np.dot(delta, weight) # Calculate error for current layer\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFbgRPTpDI9q"
      },
      "source": [
        "## Train neural network:\n",
        "\n",
        "The right values for the weights and biases determines the strength of the predictions. The process of fine-tuning the weights and biases from the input data is known as training the Neural Network. Here, X, Y, rate and weights are passed as inputs for training the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ1zEB_MwARX"
      },
      "source": [
        "def train_neuralNet(X, Y, rate, weights):\n",
        "    hidden_layers = len(weights)\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], Y[i]\n",
        "        x = np.matrix(np.append(1, x)) # Add feature vector\n",
        "        \n",
        "        output = Feed_Forward(x, weights, hidden_layers)\n",
        "        weights = BackPropagation(y, output, weights, hidden_layers)\n",
        "\n",
        "    return weights"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-yd0nqfDJyO"
      },
      "source": [
        "## Activation functions:\n",
        "\n",
        "Activation function of a node defines the output of that node, given an input or set of inputs. This output is then used as input for the next node and so on until a desired solution to the original problem is found.\n",
        "\n",
        "Activation function gets to decide which neurons will push forward the values into the next layer. Sigmoid activation function has been used for this project. It takes a value as input and outputs another value between 0 and 1. It is non-linear and easy to work with when constructing a neural network model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGwj6zoSwQwP"
      },
      "source": [
        "def Sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoidDerivative(x):\n",
        "    return np.multiply(x, 1-x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B19oEeqWDK47"
      },
      "source": [
        "## Predict:\n",
        "\n",
        "The input is first passed to the network. The higher value of a number indicates the most probable class. findMaxActivation() will find the maximum valued output and then corresponding index is set to 1. So, the predicted class is the final output class which we get from the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wc3Sj1QwTr8"
      },
      "source": [
        "def predict(item, weights):\n",
        "    hidden_layers = len(weights)\n",
        "    item = np.append(1, item)\n",
        "    \n",
        "    #forward propagation\n",
        "    output = Feed_Forward(item, weights, hidden_layers)\n",
        "    \n",
        "    final_output = output[-1].A1\n",
        "    index = findMaxActivation(final_output)\n",
        "\n",
        "    y = [0 for i in range(len(final_output))]\n",
        "    y[index] = 1\n",
        "\n",
        "    return y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dilavT14wXqy"
      },
      "source": [
        "def findMaxActivation(output):\n",
        "    m, index = output[0], 0\n",
        "    for i in range(1, len(output)):\n",
        "        if(output[i] > m):\n",
        "            m, index = output[i], i\n",
        "    \n",
        "    return index"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6nnIU6LDM8y"
      },
      "source": [
        "## Model accuracy:\n",
        "\n",
        "In this function, we will pass the inputs, outputs as well as the weights. If the predictionis correct, we will increase the count and find the accuracy by dividing the total correct predictions and total length of X. By doing these calculations, we can get the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra35ajMFwa_S"
      },
      "source": [
        "def model_accuracy(X, Y, weights):\n",
        "    correct_prediction = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], list(Y[i])\n",
        "        prediction = predict(x, weights)\n",
        "\n",
        "        if(y == prediction):\n",
        "            correct_prediction += 1\n",
        "\n",
        "    return correct_prediction / len(X)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdBMCVzSkHj"
      },
      "source": [
        "## Note:\n",
        "\n",
        "Now, we will use the cancer dataset and train the model using this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCXykrFaDN1n"
      },
      "source": [
        "## Importing the Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "qj6k_D0BCy_y",
        "outputId": "4db15b27-1b35-4a86-de1d-876377ff3613"
      },
      "source": [
        "pd.set_option('display.max_rows', 200)\n",
        "\n",
        "df = pd.read_csv('cancer_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>cell_uniformity</th>\n",
              "      <th>cellshape_uniformity</th>\n",
              "      <th>adhesion</th>\n",
              "      <th>cell_size</th>\n",
              "      <th>nuclei</th>\n",
              "      <th>chromatin</th>\n",
              "      <th>nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  clump_thickness  cell_uniformity  ...  nucleoli  mitoses  Class\n",
              "0  1000025                5                1  ...         1        1      2\n",
              "1  1002945                5                4  ...         2        1      2\n",
              "2  1015425                3                1  ...         1        1      2\n",
              "3  1016277                6                8  ...         7        1      2\n",
              "4  1017023                4                1  ...         1        1      2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO4I53o-DO1I"
      },
      "source": [
        "## Preprocessing the Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cezuqryCzIS",
        "outputId": "42433c01-5f77-41cd-b4fa-cbc297f98449"
      },
      "source": [
        "#Prepare the input data\n",
        "X = df[['clump_thickness', 'cell_uniformity', 'cellshape_uniformity', 'adhesion', 'cell_size', 'chromatin', 'nucleoli', 'mitoses']]\n",
        "X = np.array(X)\n",
        "X[:7]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  1,  1,  1,  2,  3,  1,  1],\n",
              "       [ 5,  4,  4,  5,  7,  3,  2,  1],\n",
              "       [ 3,  1,  1,  1,  2,  3,  1,  1],\n",
              "       [ 6,  8,  8,  1,  3,  3,  7,  1],\n",
              "       [ 4,  1,  1,  3,  2,  3,  1,  1],\n",
              "       [ 8, 10, 10,  8,  7,  9,  7,  1],\n",
              "       [ 1,  1,  1,  1,  2,  3,  1,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThBNVYXCCzPX",
        "outputId": "cd6103db-e310-4c8d-c5e9-984a7151bfb3"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "Y = df.Class\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
        "Y[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFTiRspjDQ8Y"
      },
      "source": [
        "## Splitting the data into train, validation and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rMdQMx0CzWU"
      },
      "source": [
        "train_index = int(0.75 * len(X))\n",
        "X_train, X_test = X[:train_index], X[train_index:]\n",
        "Y_train, Y_test = Y[:train_index], Y[train_index:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_7xnsD7CzeU"
      },
      "source": [
        "val_index = int(0.65 * len(X_train))\n",
        "X_train, X_val = X_train[:val_index], X_train[val_index:]\n",
        "Y_train, Y_val = Y_train[:val_index], Y_train[val_index:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZmUMYrUDSsb"
      },
      "source": [
        "## Train the neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T36J69n5weaY",
        "outputId": "990bb67d-ce4d-46f1-ad78-6ad968fef719"
      },
      "source": [
        "# Run it here\n",
        "features = len(X[0]) # Number of features - using all of the features except for the sequence name\n",
        "classes = len(Y[0]) # Number of classes\n",
        "\n",
        "hidden_layers = [features, 5, 10, classes]\n",
        "rate, iterations = 0.15, 500\n",
        "\n",
        "weights = neural_network(X_train, Y_train, X_val, Y_val, iterations=iterations, nodes=hidden_layers, rate=rate)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 20\n",
            "Accuracy on train data:0.9588235294117647\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 40\n",
            "Accuracy on train data:0.9529411764705882\n",
            "Accuracy on validation data:0.9293478260869565\n",
            "Iteration 60\n",
            "Accuracy on train data:0.961764705882353\n",
            "Accuracy on validation data:0.9402173913043478\n",
            "Iteration 80\n",
            "Accuracy on train data:0.9323529411764706\n",
            "Accuracy on validation data:0.9184782608695652\n",
            "Iteration 100\n",
            "Accuracy on train data:0.95\n",
            "Accuracy on validation data:0.9347826086956522\n",
            "Iteration 120\n",
            "Accuracy on train data:0.961764705882353\n",
            "Accuracy on validation data:0.9510869565217391\n",
            "Iteration 140\n",
            "Accuracy on train data:0.961764705882353\n",
            "Accuracy on validation data:0.967391304347826\n",
            "Iteration 160\n",
            "Accuracy on train data:0.9529411764705882\n",
            "Accuracy on validation data:0.9510869565217391\n",
            "Iteration 180\n",
            "Accuracy on train data:0.9205882352941176\n",
            "Accuracy on validation data:0.9510869565217391\n",
            "Iteration 200\n",
            "Accuracy on train data:0.9558823529411765\n",
            "Accuracy on validation data:0.9184782608695652\n",
            "Iteration 220\n",
            "Accuracy on train data:0.961764705882353\n",
            "Accuracy on validation data:0.9402173913043478\n",
            "Iteration 240\n",
            "Accuracy on train data:0.9529411764705882\n",
            "Accuracy on validation data:0.9510869565217391\n",
            "Iteration 260\n",
            "Accuracy on train data:0.9735294117647059\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 280\n",
            "Accuracy on train data:0.9705882352941176\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 300\n",
            "Accuracy on train data:0.9705882352941176\n",
            "Accuracy on validation data:0.967391304347826\n",
            "Iteration 320\n",
            "Accuracy on train data:0.9705882352941176\n",
            "Accuracy on validation data:0.967391304347826\n",
            "Iteration 340\n",
            "Accuracy on train data:0.9705882352941176\n",
            "Accuracy on validation data:0.9619565217391305\n",
            "Iteration 360\n",
            "Accuracy on train data:0.9676470588235294\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 380\n",
            "Accuracy on train data:0.9647058823529412\n",
            "Accuracy on validation data:0.9619565217391305\n",
            "Iteration 400\n",
            "Accuracy on train data:0.9647058823529412\n",
            "Accuracy on validation data:0.967391304347826\n",
            "Iteration 420\n",
            "Accuracy on train data:0.9647058823529412\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 440\n",
            "Accuracy on train data:0.9647058823529412\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 460\n",
            "Accuracy on train data:0.9676470588235294\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 480\n",
            "Accuracy on train data:0.9676470588235294\n",
            "Accuracy on validation data:0.9565217391304348\n",
            "Iteration 500\n",
            "Accuracy on train data:0.9441176470588235\n",
            "Accuracy on validation data:0.967391304347826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3tj2mhCTPEo"
      },
      "source": [
        "## Accuracy on Test Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27TkRXvVwwk8",
        "outputId": "b353b296-516d-4627-c258-a44c388f453f"
      },
      "source": [
        "#Final testing accuracy\n",
        "print(\"Accuracy on Test data: {}\".format(model_accuracy(X_test, Y_test, weights)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Test data: 0.9885714285714285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6ScwNKETaKA"
      },
      "source": [
        "## Predictions to cross check neural network model:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZSShUYJxB-I",
        "outputId": "c1c9cf42-ac32-44d2-c3f9-0cdbae1a59de"
      },
      "source": [
        "\n",
        "print(X_test[0], list(Y_test[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 1 1 1 2 2 1 1] [1.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkw79RB8ydpC",
        "outputId": "f756756a-1e0d-4867-b11e-527cc410b23e"
      },
      "source": [
        "print(predict(X_test[0], weights))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJQHHw1rUhJQ"
      },
      "source": [
        "## Conclusion:\n",
        "\n",
        "From these predictions, we can draw a conclusion that neural network model implemented worked pretty well on the test data and gave us a good accuracy on this dataset."
      ]
    }
  ]
}